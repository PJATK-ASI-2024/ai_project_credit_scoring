# ğŸ“Š Modeling Report -- Credit Scoring

## 1. ğŸ¯ Cel modelowania

Celem etapu modelowania byÅ‚o przygotowanie i porÃ³wnanie trzech podejÅ›Ä‡
do predykcji ryzyka kredytowego:

1.  **Model bazowy (Baseline)** -- punkt odniesienia bez prawdziwego
    uczenia.\
2.  **AutoML** -- automatyczny wybÃ³r najlepszego modelu na podstawie
    wielu klasyfikatorÃ³w.\
3.  **Model wÅ‚asny (Custom)** -- rÄ™cznie skonfigurowany Random Forest.

Modele ocenione zostaÅ‚y na zbiorze walidacyjnym za pomocÄ… metryk:

-   **accuracy**
-   **precision**
-   **recall**
-   **F1-score**
-   **ROC AUC**

------------------------------------------------------------------------

## 2. ğŸ“¦ Dane wejÅ›ciowe

Zbiory danych wykorzystane do treningu i walidacji:

-   `data/model_input/train.csv`
-   `data/model_input/val.csv`

Zmienna celu: **`loan_status`**

Do modelowania wybrano wyÅ‚Ä…cznie kolumny numeryczne.

------------------------------------------------------------------------

## 3. ğŸ§ª Modele

### 3.1. Baseline

Model: `DummyClassifier(strategy="most_frequent")`\
Cel: ustalenie minimalnego poziomu jakoÅ›ci (benchmarku).

------------------------------------------------------------------------

### 3.2. AutoML (AutoML-light)

UÅ¼yto trzech klasyfikatorÃ³w:

-   Logistic Regression\
-   RandomForestClassifier\
-   GradientBoostingClassifier

NastÄ™pnie wybrano model **o najwyÅ¼szym F1-score**.

**Wynik: najlepszy okazaÅ‚ siÄ™ model AutoML, osiÄ…gajÄ…c F1 = 0.682**

Metryki AutoML:

    {
      "accuracy": 0.8780437896459996,
      "precision": 0.7908415841584159,
      "recall": 0.599437148217636,
      "f1": 0.6819637139807898,
      "roc_auc": 0.8901723368390249
    }

------------------------------------------------------------------------

### 3.3. Model wÅ‚asny (Custom)

Model: `RandomForestClassifier`\
Wybrane hiperparametry:

-   `n_estimators = 300`
-   `max_depth = 8`
-   `min_samples_split = 4`
-   `min_samples_leaf = 2`

Metryki Custom:

    {
      "accuracy": 0.8770206670759157,
      "precision": 0.8260869565217391,
      "recall": 0.5525328330206379,
      "f1": 0.6621697582911749,
      "roc_auc": 0.8837710823910324
    }

------------------------------------------------------------------------

## 4. ğŸ“ˆ Wyniki modeli -- tabela porÃ³wnawcza

  ------------------------------------------------------------------------------
  Model           Accuracy     Precision     Recall      F1          ROC AUC
  --------------- ------------ ------------- ----------- ----------- -----------
  **Baseline**    0.782        0.000         0.000       0.000       0.500

  **AutoML**      **0.878**    0.791         **0.599**   **0.682**   **0.890**

  **Custom RF**   0.877        **0.826**     0.553       0.662       0.884
  ------------------------------------------------------------------------------

------------------------------------------------------------------------

## 5. ğŸ” Interpretacja wynikÃ³w

### â— Baseline

-   Przewiduje tylko klasÄ™ wiÄ™kszoÅ›ciowÄ… â†’ F1 = 0
-   SÅ‚uÅ¼y jako punkt odniesienia â†’ pokazuje, Å¼e zadanie nie jest
    trywialne

------------------------------------------------------------------------

### â— AutoML -- â­ najlepszy model

-   NajwyÅ¼szy F1-score (0.682) â†’ **najlepszy kompromis
    precision--recall**
-   NajwyÅ¼szy ROC AUC (0.890) â†’ najlepsza separacja klas\
-   WyÅ‚apuje najwiÄ™cej defaultÃ³w (highest recall)

**â¡ï¸ Wybrany jako najlepszy model wedÅ‚ug F1-score**\
(zgodnie z `model_comparison.json`)

------------------------------------------------------------------------

### â— Model wÅ‚asny (RandomForest)

-   NajwyÅ¼sza precision (0.826) â†’ najmniej faÅ‚szywie wykrytych
    defaultÃ³w\
-   NiÅ¼szy recall niÅ¼ AutoML â†’ bardziej konserwatywny model\
-   Dobry, jeÅ›li biznes preferuje unikanie faÅ‚szywych alarmÃ³w

------------------------------------------------------------------------

## 6. ğŸ“‰ Wizualizacje

### ğŸ–¼ 6.1. PorÃ³wnanie metryk modeli

Plik: **`docs/plots/metrics_comparison.png`**

![metrics comparison](plots/metrics_comparison.png)

------------------------------------------------------------------------

### ğŸ–¼ 6.2. WaÅ¼noÅ›Ä‡ cech -- model wÅ‚asny (RandomForest)

Plik: **`docs/plots/feature_importance.png`**

NajwaÅ¼niejsze cechy:

-   **loan_percent_income** -- najwyÅ¼szy wpÅ‚yw (35%)\
-   **loan_int_rate**\
-   **person_income**\
-   \*\*\_row_id\*\*\
-   **loan_amnt**

![feature importance](plots/feature_importance.png)

------------------------------------------------------------------------

## 7. ğŸ¥‡ WybÃ³r najlepszego modelu

Zgodnie z `model_comparison.json`:

    "best_model_by_f1": "automl"

Najlepszy model:\
\### **AutoML (GradientBoosting / RF / Logistic -- wybrany
automatycznie)**

Powody:

-   najwyÅ¼szy F1\
-   najwyÅ¼szy ROC AUC\
-   najlepsza detekcja przypadkÃ³w pozytywnych (default)

------------------------------------------------------------------------

## 8. ğŸ“ Artefakty modelowania

ZnajdujÄ… siÄ™ w katalogu:

    data/reporting/
    â”œâ”€â”€ baseline_metrics.json
    â”œâ”€â”€ automl_metrics.json
    â”œâ”€â”€ custom_metrics.json
    â”œâ”€â”€ automl_results.csv
    â””â”€â”€ model_comparison.json

------------------------------------------------------------------------

## 9. ğŸ§­ Wnioski koÅ„cowe

-   AutoML dostarcza **najlepszy ogÃ³lny model**\
-   Custom RF ma najwiÄ™kszÄ… precision â†’ dobry dla scenariuszy niskiego
    ryzyka\
-   Preprocessing oraz selekcja cech majÄ… duÅ¼y wpÅ‚yw na wyniki\
-   Pipeline modeling dziaÅ‚a w peÅ‚ni w Kedro i generuje kompletne
    artefakty raportowe

------------------------------------------------------------------------

## 10. ğŸ“… Rekomendacje na przyszÅ‚oÅ›Ä‡

-   dodaÄ‡ ewaluacjÄ™ na zbiorze testowym,\
-   przeprowadziÄ‡ analizÄ™ bÅ‚Ä™dÃ³w (false positives / negatives),\
-   wykorzystaÄ‡ SHAP do interpretacji modelu,\
-   wdroÅ¼yÄ‡ MLflow/WandB do Å›ledzenia eksperymentÃ³w.