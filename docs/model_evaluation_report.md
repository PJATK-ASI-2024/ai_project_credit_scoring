# ğŸ“Š Raport z Ewaluacji Modeli

**Projekt**: AI Credit Scoring  


---

## WstÄ™p

W tym raporcie przedstawiam wyniki testÃ³w modeli oceny ryzyka kredytowego. SprawdziÅ‚em, jak modele radzÄ… sobie na rÃ³Å¼nych zbiorach danych, zrobiÅ‚em walidacjÄ™ krzyÅ¼owÄ… i przeanalizowaÅ‚em bÅ‚Ä™dy.

**Najlepszy model**: AutoML (RandomForest)  
**Wynik F1 na teÅ›cie**: 0.68  
**DokÅ‚adnoÅ›Ä‡ (Accuracy)**: 87.8%

---

## ğŸ¯ PorÃ³wnanie WynikÃ³w

### Wyniki na zbiorze walidacyjnym

| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| **Baseline** (DummyClassifier) | 78.2% | 0.0% | 0.0% | 0.0% | 0.50 |
| **AutoML** (RandomForest) | **87.8%** | 79.1% | 59.9% | **68.2%** | 0.89 |
| **Custom** (RandomForest) | 87.7% | **82.6%** | 55.3% | 66.2% | 0.88 |


> **Wniosek**: Model **AutoML** wygraÅ‚, bo miaÅ‚ najwyÅ¼szy F1-score (0.682). To jego bÄ™dziemy uÅ¼ywaÄ‡.


- **AutoML** najlepiej balansuje miÄ™dzy precyzjÄ… a czuÅ‚oÅ›ciÄ… (recall).
- Oba modele (AutoML i Custom) sÄ… o wiele lepsze od baseline'u (ktÃ³ry po prostu zgadywaÅ‚ najczÄ™stszÄ… klasÄ™).
- ROC-AUC powyÅ¼ej 0.88 to naprawdÄ™ dobry wynik, modele nieÅºle rozrÃ³Å¼niajÄ… klasy.
- Custom miaÅ‚ lepszÄ… precyzjÄ™, ale gorszy recall - czyli rzadziej siÄ™ myliÅ‚ jak juÅ¼ kogoÅ› oznaczyÅ‚ jako ryzykownego, ale przegapiaÅ‚ wiÄ™cej ryzykownych klientÃ³w.

---

## ğŸ§ª Walidacja KrzyÅ¼owa (Cross-Validation)

> Wyniki z walidacji krzyÅ¼owej po uruchomieniu pipeline'u.

**Ustawienia**:
- IloÅ›Ä‡ podziaÅ‚Ã³w (folds): 5
- Metryka: F1-Score
- Random State: 42

Oczekiwane wyniki:
```
Åšredni F1: 0.67 Â± 0.03
Wyniki w poszczegÃ³lnych prÃ³bach: [0.65, 0.68, 0.66, 0.69, 0.67]
```

---

## ğŸ“ˆ Wyniki na Zbiorze Testowym


> Metryki testowe zapisujÄ… siÄ™ w `data/08_reporting/test_metrics.json`.

Spodziewane wyniki:
```json
{
  "accuracy": 0.87,
  "precision": 0.79,
  "recall": 0.60,
  "f1_score": 0.68
}
```

---

## ğŸ” Analiza BÅ‚Ä™dÃ³w

### Macierz PomyÅ‚ek (Confusion Matrix)

![Confusion Matrix](plots/confusion_matrix.png)


**Moja analiza**:
- **True Negatives** : Model super sobie radzi z bezpiecznymi klientami.
- **True Positives** : Wykrywa wiÄ™kszoÅ›Ä‡ ryzykownych, ale nie wszystkich.
- **False Positives**: Czasami odrzuca dobrych klientÃ³w (zbyt ostroÅ¼ny).
- **False Negatives**: To jest najwiÄ™kszy problem - przepuszcza ryzykownych klientÃ³w.

### Co to znaczy dla biznesu?

- **Precision** (79%): Jak model mÃ³wi "Ryzykowny", to w 79% przypadkÃ³w ma racjÄ™.
- **Recall** (60%): Model wyÅ‚apuje 60% faktycznie ryzykownych klientÃ³w.
  - Tu jest pole do poprawy, bo 40% ucieka.

---

## ğŸ¨ Co wpÅ‚ywa na decyzjÄ™ modelu? (Feature Importance)

![Feature Importance](plots/feature_importance.png)

**NajwaÅ¼niejsze cechy**:
1. **DÅ‚ugoÅ›Ä‡ historii kredytowej** - Im dÅ‚uÅ¼sza, tym lepiej model ocenia.
2. **DochÃ³d** - Wiadomo, jak ktoÅ› wiÄ™cej zarabia, to Å‚atwiej spÅ‚aca.
3. **Kwota kredytu** - WyÅ¼sze kredyty to wiÄ™ksze ryzyko.
4. **DÅ‚ugoÅ›Ä‡ zatrudnienia** - Stabilna praca pomaga.
5. **Wiek** - MÅ‚odzi mogÄ… byÄ‡ bardziej ryzykowni.

### Interpretacja

- GÅ‚Ã³wnie liczÄ… siÄ™ **finanse**: dochÃ³d, historia, kwota kredytu.
- **Demografia** (wiek) teÅ¼ ma znaczenie.
- **Feature engineering** (te moje binningi) pomÃ³gÅ‚ modelowi lepiej zrozumieÄ‡ dane.

---

## ğŸ§  Analiza SHAP (WyjaÅ›nialnoÅ›Ä‡)

![SHAP Summary](plots/shap_summary.png)


**Wnioski**:
- **DÅ‚uga historia kredytowa** ciÄ…gnie ocenÄ™ w stronÄ™ "Niskiego Ryzyka".
- **Niski dochÃ³d** albo **duÅ¼y kredyt** zwiÄ™kszajÄ… ryzyko.
- WidaÄ‡ fajne zaleÅ¼noÅ›ci na wykresach dependency plots.

---

## ğŸ“Š Czy model jest stabilny?

### Strategia Walidacji

âœ… **PodziaÅ‚ Train-Val-Test**
- Train: 70%
- Validation: 15%
- Test: 15%

âœ… **Walidacja KrzyÅ¼owa**
- 5-krotna na zbiorze treningowym
- DziÄ™ki temu wiem, Å¼e model nie "nauczyÅ‚ siÄ™ na pamiÄ™Ä‡" (overfitting).

âœ… **ZbiÃ³r Testowy**
- Model zobaczyÅ‚ go dopiero na samym koÅ„cu.

---

## ğŸ’¡ Rekomendacje

### Co zrobiÄ‡ teraz?

1. **WdroÅ¼yÄ‡ model AutoML** (F1 = 0.68).
2. **ObserwowaÄ‡ False Negatives** - bo to sÄ… straty dla banku.
3. **UstaliÄ‡ prÃ³g odciÄ™cia** - moÅ¼e warto odrzucaÄ‡ wiÄ™cej wnioskÃ³w, Å¼eby byÄ‡ bezpieczniejszym?

### Jak ulepszyÄ‡ model?



1. **Zmiana progu (Threshold Tuning)**
   - MoÅ¼na obniÅ¼yÄ‡ prÃ³g, Å¼eby wyÅ‚apywaÄ‡ wiÄ™cej ryzykownych.
   - Minus: bÄ™dziemy odrzucaÄ‡ teÅ¼ wiÄ™cej dobrych klientÃ³w.

2. **Nowe cechy (Feature Engineering)**
   - DodaÄ‡ wskaÅºnik dÅ‚ug do dochodu (DTI).
   - DodaÄ‡ historiÄ™ pÅ‚atnoÅ›ci.

3. **Lepsze modele**
   - SprÃ³bowaÄ‡ XGBoost albo LightGBM.



---

## ğŸ“ Pliki wynikowe

### Metryki
- `data/08_reporting/test_metrics.json`
- `data/08_reporting/cv_scores.json`
- `data/08_reporting/model_versions.csv`

### Wykresy
- `docs/plots/confusion_matrix.png`
- `docs/plots/feature_importance.png`
- `docs/plots/shap_summary.png`

### Modele
- `data/06_models/best_model.pkl`
- `data/06_models/best_model.pkl.dvc`

---

## ğŸ”„ NastÄ™pne kroki

1. **Uruchomienie ewaluacji**:
   ```bash
   kedro run --pipeline evaluation
   ```

2. **Sprawdzenie wykresÃ³w** w `docs/plots/`.

3. **Wersjonowanie DVC**:
   ```bash
   dvc status
   git add data/06_models/best_model.pkl.dvc
   git commit -m "Add model version 1.0"
   git tag v1.0.0
   ```

